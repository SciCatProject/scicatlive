{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SciCatLive","text":""},{"location":"#scicatlive","title":"SciCatLive","text":"<p>    Get set up with an instance of SciCat to explore the metadata catalog. SciCatlive provides a flexible and easy way to learn about SciCat and its features for people who are looking to integrate SciCat into their environment. For a user guide please see         original documentation        .   </p> <p>    This project requires docker and docker compose. The docker version must be later than 2.29.0 to support this project.   </p>"},{"location":"#first-stable-version","title":"First stable version","text":"<p>    Release    <code>     v3.0    </code>    is the first stable and reviewed version of SciCatLive.   </p>"},{"location":"#steps","title":"Steps","text":"Windows specific instructions (click to expand)     <p>      Running this project on Windows is not officialy supported, you should use Windows Subsystem for Linux (WSL).    </p> <p>     However, if you want to run it on Windows you have to be careful about:    </p> <ul> <li>      This project makes use of symbolic links, Windows and git for Windows have to be             configured to handle them            .     </li> <li>      End of lines, specifically in shell scripts. If you have the git config parameter      <code>       auto.crlf      </code>      set to      <code>       true      </code>      , git will   replace LF by CRLF causing shell scripts and maybe other things to fail.     </li> <li>      This project uses the variable      <code>       ${PWD}      </code>      to ease path resolution in bind mounts. In PowerShell/Command Prompt, the      <code>       PWD      </code>      environment variable doesn't exist so you would need to set in manually before running any      <code>       docker compose      </code>      command.     </li> </ul> <p> </p> <ol> <li>     Clone the repository    </li> </ol> <pre><code>git clone https://github.com/SciCatProject/scicatlive.git\n</code></pre> <ol> <li>     Run with the following command inside the directory    </li> </ol> <pre><code>docker compose up -d\n</code></pre>"},{"location":"#default-setup","title":"Default setup","text":"<p>    By running    <code>     docker compose up -d    </code>    these steps take place:   </p> <ol> <li>     the SciCat           backend v4          container is created and connected to a           mongo DB          .    </li> <li>     the SciCat           frontend          container is created and connected to (1).    </li> <li>     a reverse           proxy          container is created and routes traffic to (1) and (2) through localhost    subdomains, in the form:     <code>      http://${service}.localhost     </code>     . The frontend is available at simply     <code>      http://localhost     </code>     .    </li> <li>     Some services have additional endpoints that can be explored in SciCatLive which would follow     <code>      http://${service}.localhost/${prefix}     </code>     . For example, the backend API can be explored through a Swagger UI at     <code>      http://backend.localhost/explorer     </code>     . For more information on the paths used by these routes see the original    documentation for these services.    </li> </ol>"},{"location":"#extra-services","title":"Extra services","text":"<p>    SciCat has extra features as part of its core as well as integrating with external services.   </p> <p>    SciCat features that extend the backend are:   </p> <ul> <li>     Jobs - this mechanism posts to a           message broker          . In v3 it can then trigger           down stream processes          . To use this a RabbitMQ server is   enabled.    </li> <li>       Elasticsearch          - creates an elasticsearch service to provide full   text search in the backend.    </li> </ul> <p>    Services that can be integrated with SciCat are:   </p> <ul> <li>       LDAP          - authentication and authorization from an LDAP server    </li> <li>       OIDC          - authentication and authorization using an OIDC provider    </li> <li>       SearchAPI          - for better free text search in the metadata based on the PANOSC           search-api      </li> <li>       LandingPage          - a public interface for published datasets:           landingpage      </li> <li>       JupyterHub          - Adds an instance of JupyterHub which demonstrates ingestion and extraction of   metadata using           pyscicat          .    </li> <li>       OAIPMH          - a service for published metadata via the           OAI-PMH protocol          :           oaipmh      </li> </ul> <p>    To simply enable one or more of these extra services configure them by setting the proper environment variable(s) and/or compose profile(s) from         this table        .   </p> <p>    For a complete guide on how to customise or configure any service, including the default ones, please refer to these sections:   </p> <ul> <li>     manually           select the services      </li> <li>     use           docker compose env variables          to enable features (supported values from this           table          )    </li> <li>     use           docker compose profiles          to enable extra services (supported values from this           table          )    </li> <li>     modify the           service-specific config          to customise specific services    </li> <li>     add           entrypoints          to control startup logic    </li> </ul> <p>    For a guide on how to add a new service, please refer to         this section        .   </p>"},{"location":"#dependencies","title":"Dependencies","text":"<p>    Here below we show the dependencies, including the ones of the         extra services        (if    <code>     B    </code>    depends on    <code>     A    </code>    , then we visualize it as    <code>     A --&gt; B    </code>    ):   </p> <pre><code>graph TD\n   subgraph services\n      subgraph backend\n         backends[v3*/v4*]\n      end\n      backend --&gt; frontend\n      backend --&gt; searchapi\n      backend --&gt; landingpage\n      backend --&gt; oaipmh\n      backend --&gt; jupyter\n   end\n\n   proxy -.- services\n\n   %% CSS Styling\n   linkStyle 5 marker-end:none</code></pre> <p>    We flag with    <code>     *    </code>    the services which have extra internal dependencies, which are not shared.   </p>"},{"location":"#select-the-services","title":"Select the services","text":"<p>    The user can selectively decide the containers to spin up and the dependencies will be resolved accordingly. The available services are in the         services        folder and are called consistently.   </p> <p>    For example, one could decide to only run the    <code>     backend    </code>    by running (be aware that this will not run the    <code>     proxy    </code>    , so the service will not be available at    <code>     backend.localhost    </code>    ):   </p> <pre><code>docker compose up -d backend\n</code></pre> <p>    (or a list of services, for example, with the proxy    <code>     docker compose up -d backend proxy    </code>    )   </p> <p>    This will run, from the         previous section        , (1) and (2) but skip the rest.   </p>      Accordingly (click to expand)...     <pre><code>docker compose up -d frontend\n</code></pre> <p>     Will run, from the           previous section          , (1), (2) and (4) but skip (5).    </p> <p>     And    </p> <pre><code>docker compose --profile search up -d searchapi\n</code></pre> <p>     Will run, from the           previous section          , (1) and (2), skip (3) and (4), and add the     <code>      searchapi     </code>     service.    </p> <p>    Make sure to check the         backend compatibility        when choosing services and setting    <code>     docker compose env vars and profiles    </code>    .   </p>"},{"location":"#features","title":"Features","text":""},{"location":"#docker-compose-env-variables","title":"Docker compose env variables","text":"<p>    They are used to modify existing services where whenever enabling the feature requires changes in multiple services. They also have the advantage, compared to docker profiles, of not needing to define a new profile when a new combination of features becomes available. To set an env variable for docker compose, either assign it in the shell or change the         .env        file. To later unset it, either unset it from the shell or assign it an empty value, either in the shell or in the         .env        file.   </p> <p>    For example, to use the Jobs functionality of SciCat change    <code>     JOBS_ENABLED    </code>    to true before running your    <code>     docker compose    </code>    command or simply export it in the shell. For all env configuration options see this         section        .   </p>"},{"location":"#docker-compose-profiles","title":"Docker compose profiles","text":"<p>    They are used when adding new services or grouping services together (and do not require changes in multiple services). To enable any, run    <code>     docker compose --profile &lt;PROFILE&gt; up -d    </code>    , or export the    <code>     COMPOSE_PROFILES    </code>    env variable as described by the         docker docs        . If needed, the user can specify more than one profile in the CLI by using the flag as    <code>     --profile &lt;PROFILE1&gt; --profile &lt;PROFILE2&gt;    </code>    .   </p> <p>    For example    <code>     docker compose --profile analysis    </code>    sets up a jupyter hub with some notebooks for ingesting data into SciCat, as well as the related services (backend, proxy). For more information on profiles available in SciCat live see the following         table        .   </p>"},{"location":"#docker-compose-profiles-and-env-variables-configuration-options","title":"Docker compose profiles and env variables configuration options","text":"Type              Env key              Value: Service/Feature              Default              Backend Compatibility              Description              Other impacted services              profile       <code>        COMPOSE_PROFILES       </code> <li> <code>         analysis        </code>        : jupyter       </li> <li> <code>         search        </code>        : searchapi,landingpage,oaipmh       </li> <li> <code>         '*'        </code>        : jupyter,searchapi,landingpage,oaipmh       </li> <code>        ''       </code>        *       <li>        analysis: enables additional jupyter notebook with python SciCat SDK installed and example notebooks       </li> <li>        search: enables a SciCat interface for standardized search and a public interface for published datasets       </li>        env       <code>        BE_VERSION       </code> <li> <code>         v3        </code>        : backend/v3       </li> <li> <code>         v4        </code>        : backend/v4       </li> <code>        v4       </code>        as set              Sets the BE version to use in (2) of               default setup              to v3              mongodb,frontend              env       <code>        JOBS_ENABLED       </code> <code>        true       </code>       : rabbitmq,archivemock (v3 only),jobs feature       <code>        ''       </code>        *              Creates a RabbitMQ message broker which the BE posts to and the archivemock listens to. It emulates the data long-term archive/retrieve workflow              env       <code>        ELASTIC_ENABLED       </code> <code>        true       </code>       : elastic,elastic feature       <code>        ''       </code>        v4              Creates an elastic search service and sets the BE to use it for full-text searches              env       <code>        LDAP_ENABLED       </code> <code>        true       </code>       : ldap auth       <code>        ''       </code>        *              Creates an LDAP service and sets the BE to use it as authentication backend              env       <code>        OIDC_ENABLED       </code> <code>        true       </code>       : oidc auth       <code>        ''       </code>        *              Creates an OIDC identity provider and sets the BE to use it as authentication backend              env       <code>        DEV       </code> <code>        true       </code>       : backend,frontend,searchapi,archivemock,oaipmh,landingpage in DEV mode       <code>        ''       </code>        *              The SciCat services' environment is prepared to ease the               development in a standardized environment               env       <code>        BACKEND_DEV       </code> <code>        true       </code>       : backend,archivemock in DEV mode       <code>        ''       </code>        *              Same as       <code>        DEV=true       </code>       but limited to the backend service              env       <code>        FRONTEND_DEV       </code> <code>        true       </code>       : frontend in DEV mode       <code>        ''       </code>        *              Same as       <code>        DEV=true       </code>       but limited to the frontend service              env       <code>        SEARCHAPI_DEV       </code> <code>        true       </code>       : searchapi in DEV mode       <code>        ''       </code>        *              Same as       <code>        DEV=true       </code>       but limited to the searchapi service              env       <code>        LANDINGPAGE_DEV       </code> <code>        true       </code>       : landingpage in DEV mode       <code>        ''       </code>        *              Same as       <code>        DEV=true       </code>       but limited to the landingpage service              env       <code>        OAIPMH_DEV       </code> <code>        true       </code>       : oaipmh in DEV mode       <code>        ''       </code>        *              Same as       <code>        DEV=true       </code>       but limited to the oaipmh service              env       <code>        &lt;SERVICE&gt;_HTTPS_URL       </code> <code>        &lt;URL&gt;       </code>       : HTTPS termination       <code>        ''       </code>        *              Requests the TLS certificate for the URL to LetsEncrypt through the               proxy               env       <code>        DEV_BBACKUP       </code> <code>        true       </code>       : bidirectional synchronization of DEV volume       <code>        ''       </code>        *              Enables               DEV bidirectional synchronization              between ${PWD}/bbackup/${APP} on the host and the dev volume       <p>    After optionally setting any configuration option, one can still select the services to run as described by the         select the services        section.   </p>"},{"location":"#dev-configuration","title":"DEV configuration","text":"(click to expand)     <p>     To provide a consistent environment where developers can work, the     <code>      DEV=true     </code>     option creates the SciCat services (see DEV from the           env vars section          for the list), but instead of running them, it just creates the base environment that each service requires. For example, for the     <code>      backend     </code>     , instead of running the web server, it creates a NODE environment with     <code>      git     </code>     where one can develop and run the unit tests. This is useful as often differences in environments create collaboration problems. It should also provide an example of the configuration for running tests. Please refer to the services' README for additional information, or to the Dockerfile     <code>      CMD     </code>     of the components' GitHub repo if not specified otherwise. The     <code>      DEV=true     </code>     affects the SciCat services only. It's also possible to only run some services in development mode by using their respective variables (eg.     <code>      BACKEND_DEV=true     </code>     )    </p> <p>     Please be patient when using DEV as each container sets the env for dev, including the requirements for testing, which might take a little to finish. To see if any special precaution is required to run the tests, refer to the           compose.dev.test.yaml          file where tests files are referenced and refer to their content.           When DEV=true          , if you want to run tests when the containers start, you can do so by including the     <code>      compose.dev.test.yaml     </code>     compose file.    </p> <pre><code>docker compose -f compose.yaml -f .github/compose.dev.test.yaml ...\n</code></pre> <p>     It is very convenient if using           VSCode          , as, after the docker services are running, one can attach to it and start developing using all VSCode features, including version control and debugging.    </p> <p>     Please note that           entrypoints          when     <code>      DEV=true     </code>     are only run when the component's container is created for the first time. This is done to avoid clashes with local changes.    </p> <p>     To ease writing DEV configuration, a dev template is provided at           ./services/compose.dev.yaml          and each component inhearits from it. As you can see in the file           ./services/frontend/compose.dev.          , setting the componenent specific variables from the relative           .env file          .          Docker compose applies a           precedence mechanism          whenever the same variable is defined in     <code>      .env     </code>     files in nested folders, with precedence to the folder where the default     <code>      COMPOSE_FILE     </code>     lives. This means that the current template cannot be used in case of nested components, at least for the parts where local variables are used. There is no conflict with variables defined multiple times in     <code>      .env     </code>     files at the same level.    </p> <p>      To prevent git unpushed changes from being lost when a container is restarted, the work folder of each service, when in DEV mode, is mounted to a docker volume, with naming convention     <code>      ${COMPOSE_PROJECT_NAME}_&lt;service&gt;_dev     </code>     . Make sure, to commit and push frequently, especially before removing docker volumes to push the relevant changes.    </p> <p>      As the DEV containers pull from upstream/latest, there is no guarantee of their functioning outside of releases. If they fail to start, try, as a first option, to build the image from a tag (e.g.           build context          ) using the           TAG          and then git checkout to that tag (e.g. set           GITHUB_REPO          including the branch using the same syntax and value as the build context). You can achieve this, by setting the     <code>      GITHUB_REPO     </code>     env variable in the component     <code>      .env     </code>     file (e.g. the           frontend env file          ) as follows:    </p> <pre><code>-  GITHUB_REPO=https://github.com/SciCatProject/frontend.git\n+  GITHUB_REPO=https://github.com/SciCatProject/frontend.git#v4.4.1\n</code></pre> <p>     The repo is checkout at that particular commit only if the docker volume does not yet exist.    </p>"},{"location":"#dev-bidirectional-synchronization","title":"DEV bidirectional synchronization","text":"<p>     Setting     <code>      DEV_BBACKUP=true     </code>     in the           .env          file enables bidirectional synchronization between the DEV volume of each component (e.g.     <code>      frontend_dev     </code>     ) and a directory on the host placed at     <code>      ${PWD}/bbackup/${APP}     </code>     (e.g.     <code>      ${PWD}/bbackup/${APP}     </code>     ). This is sometimes convenient both to have a backup of the volume and to enable the use of additional tools installed on the host, which require file access.    </p>"},{"location":"#tls-configuration","title":"TLS configuration","text":"<p>    You can enable TLS termination of desired services by setting the    <code>     &lt;SERVICE&gt;_HTTPS_URL    </code>    , by setting the full URL, including    <code>     https://    </code>    . The specified HTTPS URL will get a    <code>     letsencrypt    </code>    generated certificate through the proxy setting. For more details see the         proxy instructions        . After setting some URLs, the required changes in dependent services are automatically resolved, as explained for example in the         frontend docs        . Whenever possible, we use either the docker internal network or the localhost subdomains.   </p> <p>     Please make sure to set all required    <code>     &lt;SERVICE&gt;_HTTPS_URL    </code>    whenever enabling one, as mixing public URLs and    <code>     localhost    </code>    ones might be tricky. See, for example, what is described in the         frontend documentation        and the         backend documentation        .   </p>"},{"location":"#service-specific-config","title":"Service-specific config","text":"<p>    It can be changed whenever needing to configure a service independently from the others.   </p> <p>    Every service folder (inside the         services        parent directory) contains its configuration and some instructions, at least for the non-third-party containers.   </p> <p>    For example, to configure the         frontend        , the user can change any file in the         frontend config        folder, for which instructions are available in the         README        file.   </p> <p>    After any configuration change,    <code>     docker compose up -d    </code>    must be rerun, to allow loading the changes.   </p>"},{"location":"#entrypoints","title":"Entrypoints","text":"<p>    Sometimes, it is useful to run init scripts (entrypoints) before the service starts. For example, for the    <code>     landingpage    </code>    composability, it is useful to specify its configuration through multiple JSON files, with different scopes, which are then merged by a         init script        . For this reason, one can define         common entrypoints        and service-specific ones (e.g.         backend v4 ones        ) which can be run inside the container, before the service starts (i.e. before the docker compose    <code>     command    </code>    is executed). Whenever these entrypoints are shared between services, it is recommended to place them in an    <code>     entrypoints    </code>    folder below the outermost service (e.g.         this one        ).   </p> <p>    To ease the iterative execution of multiple init scripts, one can leverage the         loop_entrypoints        utility, which loops alphabetically over    <code>     /docker-entrypoinst/*.sh    </code>    and executes each. This is in use in some services (e.g. in the         frontend        ), so one can add additional init steps by mounting them, one by one, as volumes inside the container in the    <code>     /docker-entrypoints    </code>    folder and naming them depending on the desired order (eventually rename the existing ones as well).   </p>"},{"location":"#if-the-service-does-not-support-entrypoints-yet-one-needs-to","title":"If the service does not support entrypoints yet, one needs to","text":"(click to expand):     <ol> <li>      mount the             loop_entrypoint.sh            as a volume inside the container     </li> <li>      mount any service-specific init script as a volume in the container in the folder      <code>       /docker-entrypoints/*.sh      </code>      , naming    them sequentially, depending on the desired execution order     </li> <li>      override the      <code>       entrypoint      </code>      field in the service     </li> <li>      specify the service      <code>       command      </code> </li> </ol> <p>     See for example the           frontend compose file          .    </p>"},{"location":"#add-a-new-service","title":"Add a new service","text":"<p>    Please note that services should, in general, be defined by their responsibility, rather than by their underlying technology, and should be named so.   </p>"},{"location":"#basic","title":"Basic","text":"<p>    To add a new service (see the         jupyter service        for a minimal example):   </p> <ol> <li>     create a dedicated folder in the           services          one *    </li> <li>     name it as the service    </li> <li>     create the     <code>      compose.yaml     </code>     file    </li> <li>     eventually, add a     <code>      README.md     </code>     file in the service    </li> <li>     eventually, add the platform field, as described by the           supperted OSs      </li> <li>     include the reference to (3) to the global           compose include list          *    </li> <li>     eventually, update the main           README.md      </li> </ol> <p>    * if the service to add is not shared globally, but specific to one particular service or another implementation of the same component, add it to the    <code>     services    </code>    folder relative to the affected service, and in (6) add it to its inclusion list. See an example of a service relative         services folder here        and a         relative inclusion list here        .   </p>"},{"location":"#supported-os-architectures","title":"Supported OS architectures","text":"<p>    Since some images are not built with multi-arch, in particular the SciCat ones, make sure to specify the platform of the service in the compose, when needed, to avoid possible issues when running    <code>     docker compose up    </code>    on different platforms, for example on MAC with arm64 architecture. See for example the         searchapi compose        .   </p>"},{"location":"#advanced","title":"Advanced","text":"(click to expand)     <p>     To add a new service, with advanced configuration (see the           backend          for an extensive example, or/and this           PR          which added the           landingpage          ):    </p> <ol> <li>      follow the steps from the             basic section       </li> <li>      eventually, include any service, in the service-specific folder which is specific to the service and not shared by    other, more general services, e.g. here:             ./services/backend/services/            . This folder    should also include different versions of the same service, e.g.             v3 and v4       </li> <li>      eventually, if the service supports             ENVs            , leverage the             include override            feature    from docker compose. For this:     </li> <li>      create a      <code>       compose.base.yaml      </code>      file, e.g.             ./services/backend/services/v4/compose.base.yaml            , which should       contain the      <code>       base      </code>      configuration, i.e. the one where all ENVs are unset, i.e. the features are disabled     </li> <li>      create the ENV-specific (e.g.      <code>       ELASTIC_ENABLED      </code>      )      <code>       compose.&lt;ENV&gt;.yaml      </code>      file, e.g.             backend v4 compose.elastic.yaml            , with the       additional/override config, specific to the enabled feature     </li> <li>      create a symlink from             .empty.yaml            to each      <code>       .compose.&lt;ENV&gt;.yaml      </code>      , e.g.             ./services/backend/services/v4/.compose.elastic.yaml            . This       is used whenever the      <code>       ENV      </code>      is unset, as described in the next step     </li> <li>      use      <code>       compose.yaml      </code>      to merge the      <code>       compose*.yaml      </code>      files together, making sure to default to      <code>       .compose.&lt;ENV&gt;.yaml      </code>      whenever the      <code>       ENV      </code>      is not set. See an example             ./services/backend/services/v4/compose.yaml       </li> <li>      if the service is another version of an existing one, e.g. v3 and v4 versions of the      <code>       backend      </code>      service, add the       selective include in the parent compose.yaml, e.g.             ./services/backend/compose.yaml       </li> <li> <p>       eventually, modify the               compose workflow              to add the toggle to the matrix. If       the toggle depends on the changed files, remember to create the toggle configuration               .github/changed_files.yaml              and create the               exclude              rule in the workflow.      </p> </li> <li> <p>       eventually, add entrypoints for init logics, as described by the section to               enable entrypoints              , e.g. like               ./services/backend/services/v4/compose.base.yaml              , including any               ENVs              specific logic. Remember to set the environment variable in the compose.yaml    file.      </p> </li> </ol>"},{"location":"#general-use-of-scicat","title":"General use of SciCat","text":"<p>    To use SciCat, please refer to the         original documentation        .   </p>"},{"location":"services/backend/","title":"Backend","text":""},{"location":"services/backend/#backend","title":"Backend","text":"<p>    The SciCat backend HTTP service.   </p>"},{"location":"services/backend/#configuration-options","title":"Configuration options","text":"<p>    For a list of configuration options, please look at         v3        or         v4        options.   </p>"},{"location":"services/backend/#default-configuration","title":"Default configuration","text":"<p>    By default         v4        is used.   </p>"},{"location":"services/backend/#enable-additional-features","title":"Enable additional features","text":"<p>    The    <code>     BE_VERSION    </code>    value controls which version of the backend should be started, either         v3        or         v4        (default).   </p> <p>    Setting the         BACKEND_HTTPS_URL and OIDC_ENABLED env variables        requires changing the OIDC configuration, either in the v3         compose.oidc.yaml        and         providers.oidc.json        , or the v4         env file        .   </p> <p>    Additionally, by setting the env variable    <code>     JOBS_ENABLED    </code>    , the         rabbitmq        service is started and the backend configured to connect to it.   </p>"},{"location":"services/backend/#dependencies","title":"Dependencies","text":"<p>    Here below we show the internal dependencies of the service, which are not already covered in         the root docs        (if    <code>     B    </code>    depends on    <code>     A    </code>    , then we visualize it as    <code>     A --&gt; B    </code>    ). The same subdomain to service convention applies.   </p> <p>     When setting    <code>     BACKEND_HTTPS_URL    </code>    and    <code>     OIDC_ENABLED    </code>    , you might need to also set    <code>     KEYCLOAK_HTTPS_URL    </code>    to correctly resolve the login flow redirects. A more detailed explanation for         v3        can be found here, and it is similar for v4.   </p> <pre><code>graph TD\n    mongodb --&gt; backend\n    ldap --&gt; backend\n    keycloak --&gt; backend\n    rabbitmq --&gt; backend</code></pre>"},{"location":"services/backend/services/keycloak/","title":"Keycloak","text":""},{"location":"services/backend/services/keycloak/#keycloak","title":"Keycloak","text":"<p>    OIDC is an authentication protocol that verifies user identities when they sign in to access digital resources. SciCat can use an OIDC service as third-party authentication provider.   </p>"},{"location":"services/backend/services/keycloak/#configuration-options","title":"Configuration options","text":"<p>    The Keycloak configuration is set by the         .env file        and the realm created is in         facility-realm.json file        .   </p> <p>    For an extensive list of available options see the         keyckload server docshere        .   </p> <p>     Realm creation is only done once, when the container is created.   </p>"},{"location":"services/backend/services/keycloak/#default-configuration","title":"Default configuration","text":"<p>    The default configuration         .env file        creates the    <code>     admin    </code>    user with the    <code>     admin    </code>    password. Administration web UI is available at    <code>     http://keycloak.localhost    </code> </p> <p>    Also a realm called    <code>     facility    </code>    is created with the following user and group:   </p>        Username              Password              Group              oidc-user              password              group1       <p>    The users' groups are passed to SciCat backend via the OIDC ID Token, in the claim named    <code>     accessGroups    </code>    (an array of strings). The name of the claim can be configured either in         login-callbacks.js        for v3 or with         environment variables        for v4.   </p>"},{"location":"services/backend/services/keycloak/#enable-additional-features","title":"Enable additional features","text":"<p>    Setting the         KEYCLOAK_HTTPS_URL env variable        enables changing the keycloak URL and adds to it TLS termination.   </p>"},{"location":"services/backend/services/ldap/","title":"LDAP (GLAuth)","text":""},{"location":"services/backend/services/ldap/#ldap-glauth","title":"LDAP (GLAuth)","text":"<p>    LDAP (Lightweight Directory Access Protocol) is a protocol used to access and manage directory information such as user credentials. SciCat can use LDAP as third-party authentication provider.   </p>"},{"location":"services/backend/services/ldap/#configuration-options","title":"Configuration options","text":"<p>    The GLAUth configuration is defined in the         glauth.conf file        .   </p> <p>    For an extensive list of available options see the         GLAuth docs        .   </p> <p>    You can add other users by editing the         configuration file        .   </p>"},{"location":"services/backend/services/ldap/#default-configuration","title":"Default configuration","text":"<p>    The default configuration creates the    <code>     dc=facility    </code>    domain with the following user:   </p>        Username              Password              ldap-user              password"},{"location":"services/backend/services/ldap/#enable-additional-features","title":"Enable additional features","text":"<p>    No additional features.   </p>"},{"location":"services/backend/services/mongodb/","title":"Mongodb","text":""},{"location":"services/backend/services/mongodb/#mongodb","title":"Mongodb","text":"<p>    The    <code>     mongodb    </code>    container is responsible of creating a mongodb container with initial metadata.   </p>"},{"location":"services/backend/services/mongodb/#configuration-options","title":"Configuration options","text":"<p>    All files collection created with relative data are in the         seed folder        and the init script         ./config/init.sh     </p> <p>    To add more collections during the creation of the database:   </p> <ol> <li>     add the corresponding file(s) in the folder           ./config/seed/          , keeping the convention:     <code>      filename := collectionname.json     </code>     .    </li> <li>     Start the docker container.    </li> </ol> <p>    The seeding of the DB takes place only if the DB does not exist already. To rerun seeding, please drop the database from mongo, either removing the docker volume or by running:   </p> <pre><code>docker compose exec -t mongodb mongosh --eval 'use $DB; db.dropDatabase();'\n</code></pre> <p>    These files are ingested into the database using mongo funcionalities and bypassing the backend, i.e. they are not to be taken as examples to use the backend API.   </p>"},{"location":"services/backend/services/mongodb/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration         init.sh        , the seeding creates data in the mongodb database used by the    <code>     backend    </code>    service (either         v4        , by default, or         v3        if specified otherwise by setting    <code>     BE_VERSION    </code>    ).   </p> <p>    When    <code>     BACKEND_DEV=true    </code>    (or    <code>     DEV=true    </code>    ) and    <code>     BE_VERSION=v4    </code>    the seeding writes to    <code>     dev-dacat-next    </code>    .   </p> <p>    For an explanation of how setting    <code>     BE_VERSION    </code>    changes the environment creation see the         configuration options in the root docs        .   </p>"},{"location":"services/backend/services/mongodb/#enable-additional-features","title":"Enable additional features","text":"<p>    No additional features.   </p>"},{"location":"services/backend/services/mongodb/#dependency-on-be_version","title":"Dependency on    <code>     BE_VERSION    </code>","text":"<p>    Since         v3        and         v4        connect to two different DBs, the         BE_VERSION        environment variable controls         which DB        should be seeded (    <code>     dacat    </code>    for         v3        and    <code>     dacat-next    </code>    for         v4        ).   </p>"},{"location":"services/backend/services/v3/","title":"V3","text":""},{"location":"services/backend/services/v3/#v3","title":"V3","text":"<p>    The SciCat backend v3 is the SciCat metadata catalogue RESTful API layer, built on top of the Loopback framework.   </p>"},{"location":"services/backend/services/v3/#configuration-options","title":"Configuration options","text":"<p>    The v3 backend configuration is set through files. What follows is a list of available options. Some configurations are very verbose and could be simplified, but v3 has reached end of life in favour of v4, thus there is no active development.   </p>"},{"location":"services/backend/services/v3/#datasourcesjson","title":"datasources.json","text":"<p>    It allows setting the connection to the underlying mongo database. It consists of two blocks: It consists of two blocks, the         transient one        which should not be changed and the         mongo one        for which we list the options that can be configured.   </p>"},{"location":"services/backend/services/v3/#mongo","title":"mongo","text":"<p>    TL;DR in most cases, is enough to set the desired url with the full connection string to your mongo instance.   </p>        Name              Description              Value              host              mongodb host              \"mongodb\"              port              mongodb host port              \"27017\"              url              mongodb full URL. If set, all the other options, apart from       <code>        useNewUrlParser       </code>       and       <code>        allowExtendedOperators       </code>       are discarded in favour of this one              \"\"              database              mongodb database              \"dacat\"              password              mongodb user password              \"\"              user              mongodb user password              \"\""},{"location":"services/backend/services/v3/#providersjson","title":"providers.json","text":"<p>    It allows setting the authentication providers. The    <code>     local    </code>    block sets the local accounts.   </p> <p>    Any file called providers*.json will be merged together by the         merge_json.sh        . This is done to allow better scoping of providers options.   </p>"},{"location":"services/backend/services/v3/#local","title":"local","text":"<p>    The only option available is to either enable or disable the local authentication. Remove the block if you want to disable that.   </p>"},{"location":"services/backend/services/v3/#configlocaljs","title":"config.local.js","text":"<p>    It allows setting backend-specific configurations. Here are the commonly changed options.   </p>"},{"location":"services/backend/services/v3/#exports","title":"exports","text":"Name              Description              Value              pidPrefix              prefix of the internal IDs              \"PID.SAMPLE.PREFIX\"              doiPrefix              prefix of the published DOIs              \"10.9999\"              policyPublicationShiftInYears              number of years before the data should be made open access. This is only an annotation in the metadata and no action is triggered after expiration              3              policyRetentionShiftInYears              number of years by which the data should be kept. This is only an annotation in the metadata and no action is triggered after expiration              10              site              name of the facility runnin SciCat              \"SAMPLE-SITE\"              queue              message broker flavour for the JOBs              \"rabbitmq\"              logbook.enabled              option to enable scichat              \"false\""},{"location":"services/backend/services/v3/#functional-accounts","title":"Functional Accounts","text":"<p>    There are a few functional accounts available for handling data:   </p>        Username              Password              Usage              admin              2jf70TPNZsS              Admin              ingestor              aman              Ingest datasets              archiveManager              aman              Manage archiving of datasets              proposalIngestor              aman              Ingest proposals"},{"location":"services/backend/services/v3/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration folder         config        , the backend is set to use the         mongo container        .   </p>"},{"location":"services/backend/services/v3/#enable-additional-features","title":"Enable additional features","text":"<p>    Additionally, by setting the env variable    <code>     JOBS_ENABLED    </code>    , the         archive mock        service is started and configured to connect to v3 and         rabbitmq        .   </p> <p>    If    <code>     LDAP_ENABLED    </code>    is toggled, you can use LDAP to log in with a         LDAP user        .   </p> <p>    If    <code>     OIDC_ENABLED    </code>    is toggled, you can use OIDC to log in with a         OIDC user        .   </p> <p>    With    <code>     DEV=true    </code>    , since the v3 tests are supposed to run with an empty DB, the set DB is         dacat_test        which is empty. If willing to use the seeded one later during development, just set    <code>     dacat    </code>    as database values in the file    <code>     /home/node/app/server/datasources.json    </code>    on the container.   </p>"},{"location":"services/backend/services/v3/#dependencies","title":"Dependencies","text":"<p>    Here below we show the internal dependencies of the service, which are not already covered in         the root docs        and in the         common backend docs        (if    <code>     B    </code>    depends on    <code>     A    </code>    , then we visualize as    <code>     A --&gt; B    </code>    ). The same subdomain to service convention applies.   </p> <pre><code>graph TD\n    rabbitmq --&gt; archivemock\n    backend --&gt; archivemock</code></pre>"},{"location":"services/backend/services/v3/services/archivemock/","title":"Archivemock","text":""},{"location":"services/backend/services/v3/services/archivemock/#archivemock","title":"Archivemock","text":"<p>    The Archive Mock simulates the interactions of an archival mock with SciCat.   </p>"},{"location":"services/backend/services/v3/services/archivemock/#service-requirements","title":"Service Requirements","text":"<ul> <li>       RabbitMQ      </li> <li>       backend v3          (configured to use the RabbitMQ instance above for jobs)    </li> </ul>"},{"location":"services/backend/services/v3/services/archivemock/#configuration-options","title":"Configuration options","text":"<p>    The container uses         environment variables        for configuration. These are set in         ./config/.env     </p>"},{"location":"services/backend/services/v3/services/archivemock/#default-configuration","title":"Default configuration","text":"<p>    By default, it is configured to connect to the         backend v3        container with the    <code>     admin    </code>    account, and to the         RabbitMQ        container with the    <code>     guest    </code>    account. It will then handle all archival and retrieval jobs posted to RabbitMQ, and update the corresponding Datasets accordingly in Scicat.   </p>"},{"location":"services/backend/services/v3/services/archivemock/#enable-additional-features","title":"Enable additional features","text":"<p> <code>     BACKEND_DEV=true    </code>    (or    <code>     DEV=true    </code>    ) enables running the archivemock in DEV mode.   </p> <p> <code>     JOBS_ENABLED    </code>    and    <code>     BE_VERSION=v3    </code>    creates the archivemock service which listens to messages submitted to         rabbitmq        .   </p>"},{"location":"services/backend/services/v4/","title":"V4","text":""},{"location":"services/backend/services/v4/#v4","title":"V4","text":"<p>    The SciCat backend v4 is a rewrite of the original backend, built on top of the NestJS framework.   </p>"},{"location":"services/backend/services/v4/#configuration-options","title":"Configuration options","text":"<p>    The backend-next service is mainly configured via environment variables. For an extensive list of available options see the         upstream documentation        .   </p>"},{"location":"services/backend/services/v4/#functional-accounts","title":"Functional Accounts","text":"<p>    There are a few functional accounts available for handling data:   </p>        Username              Password              Usage              admin              2jf70TPNZsS              Admin              ingestor              aman              Ingest datasets              archiveManager              aman              Manage archiving of datasets              proposalIngestor              aman              Ingest proposals"},{"location":"services/backend/services/v4/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration folder         config        , the backend is set to use the         mongo container        .   </p>"},{"location":"services/backend/services/v4/#enable-additional-features","title":"Enable additional features","text":"<p>    Additionally, by setting the env variable    <code>     ELASTIC_ENABLED    </code>    , the         elastic search        service is started and the backend is configured to connect to them.   </p> <p>    If    <code>     LDAP_ENABLED    </code>    is toggled, you can use LDAP to log in with a         LDAP user        .   </p> <p>    If    <code>     OIDC_ENABLED    </code>    is toggled, you can use OIDC to log in with a         OIDC user        .   </p> <p>    With    <code>     BACKEND_DEV=true    </code>    (or    <code>     DEV=true    </code>    ), since the container might have limited memory, it is recommended to run unit tests with the option    <code>     --runInBand    </code>    , as         ./entrypoints/tests.sh        , which makes the tests run sequentially, avoiding to fill the RAM which makes them freeze.   </p>"},{"location":"services/backend/services/v4/#dependencies","title":"Dependencies","text":"<p>    Here below we show the internal dependencies of the service, which are not already covered in         the root docs        and in the         common backend docs        (if    <code>     B    </code>    depends on    <code>     A    </code>    , then we visualize as    <code>     A --&gt; B    </code>    ). The same subdomain to service convention applies.   </p> <pre><code>graph TD\n    elasticsearch --&gt; backend</code></pre>"},{"location":"services/frontend/","title":"Frontend","text":""},{"location":"services/frontend/#frontend","title":"Frontend","text":"<p>    The SciCat frontend is the SciCat metadata catalogue web UI, built on top of the Angular framework.   </p>"},{"location":"services/frontend/#configuration-options","title":"Configuration options","text":"<p>    The frontend configuration is set by the         config files        . Files inside the         config        folder, with a    <code>     .json    </code>    extension are merged respecting the alphabetical order of the files in the         container        , with         config.v3.json        applied depending on the         BE_VERSION        . When using the frontend image &gt;=         5.5.0        , the values from         config.json in the upstream        are used as defaults.   </p> <p>    For an extensive list of available options see the         official SciCat documentation        in the SciCat frontend section.   </p>"},{"location":"services/frontend/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration         config        , the frontend is set to call the    <code>     backend service    </code>    available at    <code>     backend.localhost    </code>    (either         v4        , by default, or         v3        if specified otherwise by setting    <code>     BE_VERSION    </code>    ).   </p> <p>    For an explanation of how setting    <code>     BE_VERSION    </code>    changes the environment creation see the         configuration options in the root docs        .   </p>"},{"location":"services/frontend/#enable-additional-features","title":"Enable additional features","text":"<p>    Since there was a small breaking change from    <code>     v3    </code>    to    <code>     v4    </code>    , when connecting to the    <code>     backend    </code>    , the    <code>     BE_VERSION    </code>    value controls if         config.v3.json file        , which is applied when    <code>     BE_VERSION=v3    </code>    , should be included in the configs merge process.   </p> <p>    With    <code>     FRONTEND_DEV=true    </code>    (or    <code>     DEV=true    </code>    ), please use    <code>     npm start -- --host 0.0.0.0    </code>    . This is to allow traffic from any IP to the    <code>     frontend    </code>    component and it is necessary since the component runs in the docker network.   </p> <p>    Setting the         BACKEND_HTTPS_URL env variable        requires changing the    <code>     backend    </code>    URL used by the    <code>     frontend    </code>    . This is managed in the post_start of the frontend container         ./compose.https.yaml        .   </p> <p>     When setting    <code>     FRONTENT_HTTPS_URL    </code>    it is likely you also want to set the    <code>     BACKEND_HTTPS_URL    </code>    , to allow the communication between the two wherever the browser is accessed.   </p>"},{"location":"services/jupyter/","title":"Jupyter","text":""},{"location":"services/jupyter/#jupyter","title":"Jupyter","text":"<p>    This Jupyter Notebook instance is preconfigured with an example notebook that shows the usage of         Pyscicat        .   </p>"},{"location":"services/jupyter/#configuration-options","title":"Configuration options","text":"<p>    The         .env file        contains the environment variables for connecting to the backend service deployed by this project.   </p>"},{"location":"services/jupyter/#pyscicat-notebook","title":"Pyscicat Notebook","text":"<p>    This notebook demonstrates all the major actions Pyscicat is capable of:   </p> <ul> <li>     logging into SciCat backend    </li> <li>     dataset creation    </li> <li>     datablock creation    </li> <li>     attachment upload    </li> </ul>"},{"location":"services/jupyter/#thumbnail-image","title":"Thumbnail image","text":"<p>    An example image that is used for the attachment upload demonstration   </p>"},{"location":"services/jupyter/#default-configuration","title":"Default configuration","text":"<p>    This service is only dependant on the backend service, since it demonstrates communication with the latter through Pyscicat.   </p> <p>    The notebooks are mounted to the container from the         config/notebooks        directory. The changes to these notebooks should         not        be contributed back to this repository, unless this is intentional. In the case you want to upstream changes to these notebooks, be sure to clear all the results from them.   </p> <p>    The         main readme        covers all dependencies of this package.   </p>"},{"location":"services/jupyter/#enable-additional-features","title":"Enable additional features","text":"<p> <code>     --profile 'analysis'    </code>    instructs docker compose to create this additional service.   </p>"},{"location":"services/landingpage/","title":"Landingpage","text":""},{"location":"services/landingpage/#landingpage","title":"Landingpage","text":"<p>    The SciCat provides standardised search on published datasets via this LandingPageServer   </p>"},{"location":"services/landingpage/#configuration-options","title":"Configuration options","text":"<p>    The landingpage configuration is set by the         config files        . Files inside the         config        folder, with a    <code>     .json    </code>    extension are merged respecting the alphabetical order of the files in the         container        .   </p> <p>     Please note that         merging the config files        is a functionality provided by    <code>     SciCat Live    </code>    and is not supported natively by the    <code>     landingpage    </code>    .   </p>"},{"location":"services/landingpage/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration         config.json file        , the landingpage is set to call the    <code>     backend service    </code>    available at    <code>     backend.localhost    </code>    (either         v4        , by default, or         v3        if specified otherwise by setting    <code>     BE_VERSION    </code>    ) and use the    <code>     localhost    </code>    frontend to redirect to the datasets details from the published data detail page.   </p> <p>    For an explanation of how setting    <code>     BE_VERSION    </code>    changes the environment creation see the         configuration options in the root docs        .   </p>"},{"location":"services/landingpage/#enable-additional-features","title":"Enable additional features","text":"<p>    Setting the         BACKEND_HTTPS_URL and FRONTEND_HTTPS_URL env variables        requires changing the    <code>     backend    </code>    and the    <code>     frontend    </code>    URL used by the    <code>     landingpage    </code>    . This is managed in the entrypoint         ../../entrypoints/merge_json.sh        .   </p> <p>     When setting    <code>     LANDINGPAGE_HTTPS_URL    </code>    it is likely you also want to set the    <code>     BACKEND_HTTPS_URL    </code>    and    <code>     FRONTEND_HTTPS_URL    </code>    , to allow the communication between the two wherever the browser is accessed.   </p> <p>    With    <code>     LANDINGPAGE_DEV=true    </code>    (or    <code>     DEV=true    </code>    ), please use    <code>     npm start -- --host 0.0.0.0    </code>    . This is to allow traffic from any IP to the    <code>     landingpage    </code>    component and it is necessary since the component runs in the docker network.   </p> <p> <code>     --profile 'search'    </code>    instructs docker compose to create this additional service.   </p>"},{"location":"services/oaipmh/","title":"Oaipmh","text":""},{"location":"services/oaipmh/#oaipmh","title":"Oaipmh","text":"<p>    SciCat supports querying published metadata via the         OAI-PMH protocol     </p>"},{"location":"services/oaipmh/#configuration-options","title":"Configuration options","text":"<p>    The oaipmh configuration is set by the         config files        .   </p>"},{"location":"services/oaipmh/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration         .env file        , the oaipmh is set to call the    <code>     backend service    </code>    available at    <code>     backend.localhost    </code>    (either         v4        , by default, or         v3        if specified otherwise by setting    <code>     BE_VERSION    </code>    ).   </p> <p>    For an explanation of how setting    <code>     BE_VERSION    </code>    changes the environment creation see the         configuration options in the root docs        .   </p>"},{"location":"services/oaipmh/#enable-additional-features","title":"Enable additional features","text":"<p>    Setting the         BACKEND_HTTPS_URL env variables        requires changing the    <code>     backend    </code>    URL used by the    <code>     oaimph    </code>    . This is managed in the env file         ./config/.env        .   </p> <p>     When setting    <code>     OAIPMH_HTTPS_URL    </code>    it is likely you also want to set the    <code>     BACKEND_HTTPS_URL    </code>    , to allow the communication between the two wherever the browser is accessed.   </p> <p> <code>     --profile 'search'    </code>    instructs docker compose to create this additional service.   </p>"},{"location":"services/oaipmh/#dev-configuration","title":"DEV configuration","text":"<p>    Running the service in DEV mode is supported, but be aware that the upstream tests fail, so    <code>     npm run test    </code>    will fail in the scicatlive oaipmh container as well.   </p>"},{"location":"services/proxy/","title":"Proxy","text":""},{"location":"services/proxy/#proxy","title":"Proxy","text":"<p>    The proxy acts as a reverse proxy to the SciCat Live containers.   </p>"},{"location":"services/proxy/#configuration-options","title":"Configuration options","text":""},{"location":"services/proxy/#env-file","title":".env file","text":"<p>    It sets proxy options which are rarely changed, for example, the default configuration with the docker network.   </p>"},{"location":"services/proxy/#tlsenv-file","title":".tls.env file","text":"<p>    It can be customized to set the TLS options. This has an effect only if the service URLs exposed by traefik are reachable from the public web.   </p> <p>    You need to set the letsencrypt options in the         ./config/.tls.env        file.   </p>"},{"location":"services/proxy/#default-configuration","title":"Default configuration","text":"<p>    By default, all services are exposed on localhost with no TLS termination, and following the convention:   </p> <ul> <li>     frontend:     <code>      http://localhost     </code> </li> <li>     other services:     <code>      http://{service}.localhost     </code> </li> </ul>"},{"location":"services/proxy/#enable-additional-features","title":"Enable additional features","text":"<p>    To enable TLS on specific services, you can set the    <code>     &lt;SERVICE&gt;_HTTPS_URL    </code>    env var to the desired URL, including the    <code>     https://    </code>    prefix, making sure that the URLs are reachable by    <code>     letsencrypt    </code>    . See the root .env         ../../.env        for an example. This will request the certificate from    <code>     letsencrypt    </code>    .   </p>"},{"location":"services/searchapi/","title":"Searchapi","text":""},{"location":"services/searchapi/#searchapi","title":"Searchapi","text":"<p>    The SciCat seachAPI is the SciCat metadata catalogue standardised API for communication between SciCat and the PaN portal, built on top of the Loobpack framework.   </p>"},{"location":"services/searchapi/#configuration-options","title":"Configuration options","text":"<p>    The searchapi configuration is set by the         .env file        . For an extensive list of available options see the         upstream documentation        .   </p>"},{"location":"services/searchapi/#default-configuration","title":"Default configuration","text":"<p>    In the default configuration         .env file        , the searchapi is set to call the    <code>     backend service    </code>    available at    <code>     backend.localhost    </code>    (either         v4        , by default, or         v3        if specified otherwise by setting    <code>     BE_VERSION    </code>    ).   </p> <p>    For an explanation of how setting    <code>     BE_VERSION    </code>    changes the environment creation see the         configuration options in the root docs        .   </p>"},{"location":"services/searchapi/#enable-additional-features","title":"Enable additional features","text":"<p> <code>     SEARCHAPI_DEV=true    </code>    (or    <code>     DEV=true    </code>    ) enables running the archivemock in DEV mode.   </p> <p> <code>     --profile 'search'    </code>    instructs docker compose to create this additional service.   </p>"}]}